{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![CMCC](http://cmcc.ufabc.edu.br/images/logo_site.jpg)\n",
    "# **Regressão Linear**\n",
    "\n",
    "#### Este notebook mostra uma implementação básica de Regressão Linear e o uso da biblioteca [MLlib](http://spark.apache.org/docs/1.4.0/api/python/pyspark.ml.html) do PySpark para a tarefa de regressão na base de dados [Million Song Dataset](http://labrosa.ee.columbia.edu/millionsong/) do repositório [UCI Machine Learning Repository](https://archive.ics.uci.edu/ml/datasets/YearPredictionMSD). Nosso objetivo é predizer o ano de uma música através dos seus atributos de áudio.\n",
    "\n",
    "#### ** Neste notebook: **\n",
    "+  ####*Parte 1:* Leitura e *parsing* da base de dados\n",
    " + #### *Visualização 1:* Atributos\n",
    " + #### *Visualização 2:* Deslocamento das variáveis de interesse\n",
    "+  ####*Parte 2:* Criar um preditor de referência\n",
    " + #### *Visualização 3:* Valores Preditos vs. Verdadeiros\n",
    "+  ####*Parte 3:* Treinar e avaliar um modelo de regressão linear\n",
    " + #### *Visualização 4:* Erro de Treino\n",
    "+  ####*Parte 4:* Treinar usando MLlib e ajustar os hiperparâmetros\n",
    " + #### *Visualização 5:* Predições do Melhor modelo\n",
    " + #### *Visualização 6:* Mapa de calor dos hiperparâmetros\n",
    "+  ####*Parte 5:* Adicionando interações entre atributos\n",
    "+  ####*Parte 6:* Aplicando na base de dados de Crimes de São Francisco\n",
    " \n",
    "#### Para referência, consulte os métodos relevantes do PySpark em [Spark's Python API](https://spark.apache.org/docs/latest/api/python/pyspark.html#pyspark.RDD) e do NumPy em [NumPy Reference](http://docs.scipy.org/doc/numpy/reference/index.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ** Parte 1: Leitura e *parsing* da base de dados**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ** (1a) Verificando os dados disponíveis **\n",
    "\n",
    "#### Os dados da base que iremos utilizar estão armazenados em um arquivo texto. No primeiro passo vamos transformar os dados textuais em uma RDD e verificar a formatação dos mesmos. Altere a segunda célula para verificar quantas amostras existem nessa base de dados utilizando o método  [count method](https://spark.apache.org/docs/latest/api/python/pyspark.html#pyspark.RDD.count).\n",
    "\n",
    "#### Reparem que o rótulo dessa base é o primeiro registro, representando o ano."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# carregar base de dados\n",
    "from test_helper import Test\n",
    "import os.path\n",
    "baseDir = os.path.join('Data')\n",
    "inputPath = os.path.join('Aula04', 'millionsong.txt')\n",
    "fileName = os.path.join(baseDir, inputPath)\n",
    "\n",
    "numPartitions = 2\n",
    "rawData = sc.textFile(fileName, numPartitions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# EXERCICIO\n",
    "numPoints = rawData.<COMPLETAR>\n",
    "print numPoints\n",
    "samplePoints = rawData.take(5)\n",
    "print samplePoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# TEST Load and check the data (1a)\n",
    "Test.assertEquals(numPoints, 6724, 'incorrect value for numPoints')\n",
    "Test.assertEquals(len(samplePoints), 5, 'incorrect length for samplePoints')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ** (1b) Usando `LabeledPoint` **\n",
    "#### Na MLlib, bases de dados rotuladas devem ser armazenadas usando o objeto [LabeledPoint](https://spark.apache.org/docs/latest/api/python/pyspark.mllib.html#pyspark.mllib.regression.LabeledPoint).  Escreva a função `parsePoint` que recebe como entrada uma amostra de dados, transforma os dados usandoo comando [unicode.split](https://docs.python.org/2/library/string.html#string.split), e retorna um `LabeledPoint`.  \n",
    "\n",
    "#### Aplique essa função na variável `samplePoints` da célula anterior e imprima os atributos e rótulo utilizando os atributos `LabeledPoint.features` e `LabeledPoint.label`. Finalmente, calcule o número de atributos nessa base de dados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pyspark.mllib.regression import LabeledPoint\n",
    "import numpy as np\n",
    "\n",
    "# Here is a sample raw data point:\n",
    "# '2001.0,0.884,0.610,0.600,0.474,0.247,0.357,0.344,0.33,0.600,0.425,0.60,0.419'\n",
    "# In this raw data point, 2001.0 is the label, and the remaining values are features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# EXERCICIO\n",
    "def parsePoint(line):\n",
    "    \"\"\"Converts a comma separated unicode string into a `LabeledPoint`.\n",
    "\n",
    "    Args:\n",
    "        line (unicode): Comma separated unicode string where the first element is the label and the\n",
    "            remaining elements are features.\n",
    "\n",
    "    Returns:\n",
    "        LabeledPoint: The line is converted into a `LabeledPoint`, which consists of a label and\n",
    "            features.\n",
    "    \"\"\"\n",
    "    Point = <COMPLETAR>\n",
    "    return LabeledPoint(<COMPLETAR>)\n",
    "\n",
    "parsedSamplePoints = map(parsePoint,samplePoints)\n",
    "firstPointFeatures = parsedSamplePoints[0].features\n",
    "firstPointLabel = parsedSamplePoints[0].label\n",
    "print firstPointFeatures, firstPointLabel\n",
    "\n",
    "d = len(firstPointFeatures)\n",
    "print d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# TEST Using LabeledPoint (1b)\n",
    "Test.assertTrue(isinstance(firstPointLabel, float), 'label must be a float')\n",
    "expectedX0 = [0.8841,0.6105,0.6005,0.4747,0.2472,0.3573,0.3441,0.3396,0.6009,0.4257,0.6049,0.4192]\n",
    "Test.assertTrue(np.allclose(expectedX0, firstPointFeatures, 1e-4, 1e-4),\n",
    "                'incorrect features for firstPointFeatures')\n",
    "Test.assertTrue(np.allclose(2001.0, firstPointLabel), 'incorrect label for firstPointLabel')\n",
    "Test.assertTrue(d == 12, 'incorrect number of features')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Visualização 1: Atributos**\n",
    "\n",
    "#### A próxima célula mostra uma forma de visualizar os atributos através de um mapa de calor. Nesse mapa mostramos os 50 primeiros objetos e seus atributos representados por tons de cinza, sendo o branco representando o valor 0 e o preto representando o valor 1.\n",
    "\n",
    "#### Esse tipo de visualização ajuda a perceber a variação dos valores dos atributos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "\n",
    "sampleMorePoints = rawData.take(50)\n",
    "\n",
    "parsedSampleMorePoints = map(parsePoint, sampleMorePoints)\n",
    "dataValues = map(lambda lp: lp.features.toArray(), parsedSampleMorePoints)\n",
    "\n",
    "def preparePlot(xticks, yticks, figsize=(10.5, 6), hideLabels=False, gridColor='#999999',\n",
    "                gridWidth=1.0):\n",
    "    \"\"\"Template for generating the plot layout.\"\"\"\n",
    "    plt.close()\n",
    "    fig, ax = plt.subplots(figsize=figsize, facecolor='white', edgecolor='white')\n",
    "    ax.axes.tick_params(labelcolor='#999999', labelsize='10')\n",
    "    for axis, ticks in [(ax.get_xaxis(), xticks), (ax.get_yaxis(), yticks)]:\n",
    "        axis.set_ticks_position('none')\n",
    "        axis.set_ticks(ticks)\n",
    "        axis.label.set_color('#999999')\n",
    "        if hideLabels: axis.set_ticklabels([])\n",
    "    plt.grid(color=gridColor, linewidth=gridWidth, linestyle='-')\n",
    "    map(lambda position: ax.spines[position].set_visible(False), ['bottom', 'top', 'left', 'right'])\n",
    "    return fig, ax\n",
    "\n",
    "# generate layout and plot\n",
    "fig, ax = preparePlot(np.arange(.5, 11, 1), np.arange(.5, 49, 1), figsize=(8,7), hideLabels=True,\n",
    "                      gridColor='#eeeeee', gridWidth=1.1)\n",
    "image = plt.imshow(dataValues,interpolation='nearest', aspect='auto', cmap=cm.Greys)\n",
    "for x, y, s in zip(np.arange(-.125, 12, 1), np.repeat(-.75, 12), [str(x) for x in range(12)]):\n",
    "    plt.text(x, y, s, color='#999999', size='10')\n",
    "plt.text(4.7, -3, 'Feature', color='#999999', size='11'), ax.set_ylabel('Observation')\n",
    "pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **(1c) Deslocando os rótulos **\n",
    "\n",
    "#### Para melhor visualizar as soluções obtidas, calcular o erro de predição e visualizar a relação dos atributos com os rótulos, costuma-se deslocar os rótulos para iniciarem em zero.\n",
    "\n",
    "#### Dessa forma vamos verificar qual é a faixa de valores dos rótulos e, em seguida, subtrair os rótulos pelo menor valor encontrado. Em alguns casos também pode ser interessante normalizar tais valores dividindo pelo valor máximo dos rótulos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# EXERCICIO\n",
    "parsedDataInit = rawData.<COMPLETAR>\n",
    "onlyLabels = parsedDataInit.<COMPLETAR>\n",
    "minYear = onlyLabels.<COMPLETAR>\n",
    "maxYear = onlyLabels.<COMPLETAR>\n",
    "print maxYear, minYear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# TEST Find the range (1c)\n",
    "Test.assertEquals(len(parsedDataInit.take(1)[0].features), 12,\n",
    "                  'unexpected number of features in sample point')\n",
    "sumFeatTwo = parsedDataInit.map(lambda lp: lp.features[2]).sum()\n",
    "Test.assertTrue(np.allclose(sumFeatTwo, 3158.96224351), 'parsedDataInit has unexpected values')\n",
    "yearRange = maxYear - minYear\n",
    "Test.assertTrue(yearRange == 89, 'incorrect range for minYear to maxYear')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# EXERCICIO\n",
    "parsedData = parsedDataInit.<COMPLETAR>\n",
    "\n",
    "# Should be a LabeledPoint\n",
    "print type(parsedData.take(1)[0])\n",
    "# View the first point\n",
    "print '\\n{0}'.format(parsedData.take(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# TEST Shift labels (1d)\n",
    "oldSampleFeatures = parsedDataInit.take(1)[0].features\n",
    "newSampleFeatures = parsedData.take(1)[0].features\n",
    "Test.assertTrue(np.allclose(oldSampleFeatures, newSampleFeatures),\n",
    "                'new features do not match old features')\n",
    "sumFeatTwo = parsedData.map(lambda lp: lp.features[2]).sum()\n",
    "Test.assertTrue(np.allclose(sumFeatTwo, 3158.96224351), 'parsedData has unexpected values')\n",
    "minYearNew = parsedData.map(lambda lp: lp.label).min()\n",
    "maxYearNew = parsedData.map(lambda lp: lp.label).max()\n",
    "Test.assertTrue(minYearNew == 0, 'incorrect min year in shifted data')\n",
    "Test.assertTrue(maxYearNew == 89, 'incorrect max year in shifted data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ** (1d) Conjuntos de treino, validação e teste **\n",
    "\n",
    "#### Como próximo passo, vamos dividir nossa base de dados em conjunto de treino, validação e teste conforme discutido em sala de aula. Use o método [randomSplit method](https://spark.apache.org/docs/latest/api/python/pyspark.html#pyspark.RDD.randomSplit) com os pesos (weights) e a semente aleatória (seed) especificados na célula abaixo parar criar a divisão das bases. Em seguida, utilizando o método `cache()` faça o pré-armazenamento da base processada.\n",
    "\n",
    "#### Esse comando faz o processamento da base através das transformações e armazena em um novo RDD que pode ficar armazenado em memória, se couber, ou em um arquivo temporário."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# EXERCICIO\n",
    "weights = [.8, .1, .1]\n",
    "seed = 42\n",
    "parsedTrainData, parsedValData, parsedTestData = parsedData.<COMPLETAR>\n",
    "parsedTrainData.<COMPLETAR>\n",
    "parsedValData.<COMPLETAR>\n",
    "parsedTestData.<COMPLETAR>\n",
    "nTrain = parsedTrainData.count()\n",
    "nVal = parsedValData.count()\n",
    "nTest = parsedTestData.count()\n",
    "\n",
    "print nTrain, nVal, nTest, nTrain + nVal + nTest\n",
    "print parsedData.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# TEST Training, validation, and test sets (1e)\n",
    "Test.assertEquals(parsedTrainData.getNumPartitions(), numPartitions,\n",
    "                  'parsedTrainData has wrong number of partitions')\n",
    "Test.assertEquals(parsedValData.getNumPartitions(), numPartitions,\n",
    "                  'parsedValData has wrong number of partitions')\n",
    "Test.assertEquals(parsedTestData.getNumPartitions(), numPartitions,\n",
    "                  'parsedTestData has wrong number of partitions')\n",
    "Test.assertEquals(len(parsedTrainData.take(1)[0].features), 12,\n",
    "                  'parsedTrainData has wrong number of features')\n",
    "sumFeatTwo = (parsedTrainData\n",
    "              .map(lambda lp: lp.features[2])\n",
    "              .sum())\n",
    "sumFeatThree = (parsedValData\n",
    "                .map(lambda lp: lp.features[3])\n",
    "                .reduce(lambda x, y: x + y))\n",
    "sumFeatFour = (parsedTestData\n",
    "               .map(lambda lp: lp.features[4])\n",
    "               .reduce(lambda x, y: x + y))\n",
    "Test.assertTrue(np.allclose([sumFeatTwo, sumFeatThree, sumFeatFour],\n",
    "                            2526.87757656, 297.340394298, 184.235876654),\n",
    "                'parsed Train, Val, Test data has unexpected values')\n",
    "Test.assertTrue(nTrain + nVal + nTest == 6724, 'unexpected Train, Val, Test data set size')\n",
    "Test.assertEquals(nTrain, 5371, 'unexpected value for nTrain')\n",
    "Test.assertEquals(nVal, 682, 'unexpected value for nVal')\n",
    "Test.assertEquals(nTest, 671, 'unexpected value for nTest')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ** Part 2: Criando o modelo de *baseline* **"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **(2a) Rótulo médio **\n",
    "\n",
    "#### O baseline é útil para verificarmos que nosso modelo de regressão está funcionando. Ele deve ser um modelo bem simples que qualquer algoritmo possa fazer melhor.\n",
    "\n",
    "#### Um baseline muito utilizado é fazer a mesma predição independente dos dados analisados utilizando o rótulo médio do conjunto de treino. Calcule a média dos rótulos deslocados para a base de treino, utilizaremos esse valor posteriormente para comparar o erro de predição.  Use um método apropriado para essa tarefa, consulte o [RDD API](https://spark.apache.org/docs/latest/api/python/pyspark.html#pyspark.RDD)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# EXERCICIO\n",
    "averageTrainYear = (parsedTrainData\n",
    "                    .<COMPLETAR>\n",
    "                    .<COMPLETAR>\n",
    "                   )\n",
    "print averageTrainYear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# TEST Average label (2a)\n",
    "Test.assertTrue(np.allclose(averageTrainYear, 53.9316700801),\n",
    "                'incorrect value for averageTrainYear')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **(2b) Erro quadrático médio **\n",
    "\n",
    "#### Para comparar a performance em problemas de regressão, geralmente é utilizado o Erro Quadrático Médio ([RMSE](http://en.wikipedia.org/wiki/Root-mean-square_deviation)).  Implemente uma função que calcula o RMSE a partir de um RDD de tuplas (rótulo, predição)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# EXERCICIO\n",
    "def squaredError(label, prediction):\n",
    "    \"\"\"Calculates the the squared error for a single prediction.\n",
    "\n",
    "    Args:\n",
    "        label (float): The correct value for this observation.\n",
    "        prediction (float): The predicted value for this observation.\n",
    "\n",
    "    Returns:\n",
    "        float: The difference between the `label` and `prediction` squared.\n",
    "    \"\"\"\n",
    "    return <COMPLETAR>\n",
    "\n",
    "def calcRMSE(labelsAndPreds):\n",
    "    \"\"\"Calculates the root mean squared error for an `RDD` of (label, prediction) tuples.\n",
    "\n",
    "    Args:\n",
    "        labelsAndPred (RDD of (float, float)): An `RDD` consisting of (label, prediction) tuples.\n",
    "\n",
    "    Returns:\n",
    "        float: The square root of the mean of the squared errors.\n",
    "    \"\"\"\n",
    "    return <COMPLETAR>\n",
    "\n",
    "labelsAndPreds = sc.parallelize([(3., 1.), (1., 2.), (2., 2.)])\n",
    "# RMSE = sqrt[((3-1)^2 + (1-2)^2 + (2-2)^2) / 3] = 1.291\n",
    "exampleRMSE = calcRMSE(labelsAndPreds)\n",
    "print exampleRMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# TEST Root mean squared error (2b)\n",
    "Test.assertTrue(np.allclose(squaredError(3, 1), 4.), 'incorrect definition of squaredError')\n",
    "Test.assertTrue(np.allclose(exampleRMSE, 1.29099444874), 'incorrect value for exampleRMSE')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **(2c) RMSE do baseline para os conjuntos de treino, validação e teste **\n",
    "\n",
    "#### Vamos calcular o RMSE para nossa baseline. Primeiro crie uma RDD de (rótulo, predição) para cada conjunto, e então chame a função `calcRMSE`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# EXERCICIO\n",
    "labelsAndPredsTrain = parsedTrainData.<COMPLETAR>\n",
    "rmseTrainBase = calcRMSE(labelsAndPredsTrain)\n",
    "\n",
    "labelsAndPredsVal = parsedValData.<COMPLETAR>\n",
    "rmseValBase = calcRMSE(labelsAndPredsVal)\n",
    "\n",
    "labelsAndPredsTest = parsedTestData.<COMPLETAR>\n",
    "rmseTestBase = calcRMSE(labelsAndPredsTest)\n",
    "\n",
    "print 'Baseline Train RMSE = {0:.3f}'.format(rmseTrainBase)\n",
    "print 'Baseline Validation RMSE = {0:.3f}'.format(rmseValBase)\n",
    "print 'Baseline Test RMSE = {0:.3f}'.format(rmseTestBase)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# TEST Training, validation and test RMSE (2c)\n",
    "Test.assertTrue(np.allclose([rmseTrainBase, rmseValBase, rmseTestBase],\n",
    "                            [21.305869, 21.586452, 22.136957]), 'incorrect RMSE value')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ** Visualização 2: Predição vs. real **\n",
    "\n",
    "#### Vamos visualizar as predições no conjunto de validação. Os gráficos de dispersão abaixo plotam os pontos com a coordenada X sendo o valor predito pelo modelo e a coordenada Y o valor real do rótulo.\n",
    "\n",
    "#### O primeiro gráfico mostra a situação ideal, um modelo que acerta todos os rótulos. O segundo gráfico mostra o desempenho do modelo baseline. As cores dos pontos representam o erro quadrático daquela predição, quanto mais próxima do laranja, maior o erro."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from matplotlib.colors import ListedColormap, Normalize\n",
    "from matplotlib.cm import get_cmap\n",
    "cmap = get_cmap('YlOrRd')\n",
    "norm = Normalize()\n",
    "\n",
    "actual = np.asarray(parsedValData\n",
    "                    .map(lambda lp: lp.label)\n",
    "                    .collect())\n",
    "error = np.asarray(parsedValData\n",
    "                   .map(lambda lp: (lp.label, lp.label))\n",
    "                   .map(lambda (l, p): squaredError(l, p))\n",
    "                   .collect())\n",
    "clrs = cmap(np.asarray(norm(error)))[:,0:3]\n",
    "\n",
    "fig, ax = preparePlot(np.arange(0, 100, 20), np.arange(0, 100, 20))\n",
    "plt.scatter(actual, actual, s=14**2, c=clrs, edgecolors='#888888', alpha=0.75, linewidths=0.5)\n",
    "ax.set_xlabel('Predicted'), ax.set_ylabel('Actual')\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predictions = np.asarray(parsedValData\n",
    "                         .map(lambda lp: averageTrainYear)\n",
    "                         .collect())\n",
    "error = np.asarray(parsedValData\n",
    "                   .map(lambda lp: (lp.label, averageTrainYear))\n",
    "                   .map(lambda (l, p): squaredError(l, p))\n",
    "                   .collect())\n",
    "norm = Normalize()\n",
    "clrs = cmap(np.asarray(norm(error)))[:,0:3]\n",
    "\n",
    "fig, ax = preparePlot(np.arange(53.0, 55.0, 0.5), np.arange(0, 100, 20))\n",
    "ax.set_xlim(53, 55)\n",
    "plt.scatter(predictions, actual, s=14**2, c=clrs, edgecolors='#888888', alpha=0.75, linewidths=0.3)\n",
    "ax.set_xlabel('Predicted'), ax.set_ylabel('Actual')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ** Parte 3: Treinando e avaliando o modelo de regressão linear **"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ** (3a) Gradiente do erro **\n",
    "\n",
    "#### Vamos implementar a regressão linear através do gradiente descendente.\n",
    "#### Lembrando que para atualizar o peso da regressão linear fazemos: $$ \\scriptsize \\mathbf{w}_{i+1} = \\mathbf{w}_i - \\alpha_i \\sum_j (\\mathbf{w}_i^\\top\\mathbf{x}_j  - y_j) \\mathbf{x}_j \\,.$$ onde $ \\scriptsize i $ é a iteração do algoritmo, e $ \\scriptsize j $ é o objeto sendo observado no momento.\n",
    "\n",
    "#### Primeiro, implemente uma função que calcula esse gradiente do erro para certo objeto: $ \\scriptsize (\\mathbf{w}^\\top \\mathbf{x} - y) \\mathbf{x} \\, ,$ e teste a função em dois exemplos. Use o método `DenseVector` [dot](http://spark.apache.org/docs/latest/api/python/pyspark.mllib.html#pyspark.mllib.linalg.DenseVector.dot) para representar a lista de atributos (ele tem funcionalidade parecida com o `np.array()`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pyspark.mllib.linalg import DenseVector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# EXERCICIO\n",
    "def gradientSummand(weights, lp):\n",
    "    \"\"\"Calculates the gradient summand for a given weight and `LabeledPoint`.\n",
    "\n",
    "    Note:\n",
    "        `DenseVector` behaves similarly to a `numpy.ndarray` and they can be used interchangably\n",
    "        within this function.  For example, they both implement the `dot` method.\n",
    "\n",
    "    Args:\n",
    "        weights (DenseVector): An array of model weights (betas).\n",
    "        lp (LabeledPoint): The `LabeledPoint` for a single observation.\n",
    "\n",
    "    Returns:\n",
    "        DenseVector: An array of values the same length as `weights`.  The gradient summand.\n",
    "    \"\"\"\n",
    "    return <COMPLETAR>\n",
    "\n",
    "exampleW = DenseVector([1, 1, 1])\n",
    "exampleLP = LabeledPoint(2.0, [3, 1, 4])\n",
    "\n",
    "summandOne = gradientSummand(exampleW, exampleLP)\n",
    "print summandOne\n",
    "\n",
    "exampleW = DenseVector([.24, 1.2, -1.4])\n",
    "exampleLP = LabeledPoint(3.0, [-1.4, 4.2, 2.1])\n",
    "summandTwo = gradientSummand(exampleW, exampleLP)\n",
    "print summandTwo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# TEST Gradient summand (3a)\n",
    "Test.assertTrue(np.allclose(summandOne, [18., 6., 24.]), 'incorrect value for summandOne')\n",
    "Test.assertTrue(np.allclose(summandTwo, [1.7304,-5.1912,-2.5956]), 'incorrect value for summandTwo')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ** (3b) Use os pesos para fazer a predição **\n",
    "#### Agora, implemente a função  `getLabeledPredictions` que recebe como parâmetro o conjunto de pesos e um `LabeledPoint` e retorna uma tupla (rótulo, predição). Lembre-se que podemos predizer um rótulo calculando o produto interno dos pesos com os atributos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# EXERCICIO\n",
    "def getLabeledPrediction(weights, observation):\n",
    "    \"\"\"Calculates predictions and returns a (label, prediction) tuple.\n",
    "\n",
    "    Note:\n",
    "        The labels should remain unchanged as we'll use this information to calculate prediction\n",
    "        error later.\n",
    "\n",
    "    Args:\n",
    "        weights (np.ndarray): An array with one weight for each features in `trainData`.\n",
    "        observation (LabeledPoint): A `LabeledPoint` that contain the correct label and the\n",
    "            features for the data point.\n",
    "\n",
    "    Returns:\n",
    "        tuple: A (label, prediction) tuple.\n",
    "    \"\"\"\n",
    "    return <COMPLETAR>\n",
    "\n",
    "weights = np.array([1.0, 1.5])\n",
    "predictionExample = sc.parallelize([LabeledPoint(2, np.array([1.0, .5])),\n",
    "                                    LabeledPoint(1.5, np.array([.5, .5]))])\n",
    "labelsAndPredsExample = predictionExample.map(lambda lp: getLabeledPrediction(weights, lp))\n",
    "print labelsAndPredsExample.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# TEST Use weights to make predictions (3b)\n",
    "Test.assertEquals(labelsAndPredsExample.collect(), [(2.0, 1.75), (1.5, 1.25)],\n",
    "                  'incorrect definition for getLabeledPredictions')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ** (3c) Gradiente descendente **\n",
    "#### Finalmente, implemente o algoritmo gradiente descendente para regressão linear e teste a função em um exemplo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# EXERCICIO\n",
    "def linregGradientDescent(trainData, numIters):\n",
    "    \"\"\"Calculates the weights and error for a linear regression model trained with gradient descent.\n",
    "\n",
    "    Note:\n",
    "        `DenseVector` behaves similarly to a `numpy.ndarray` and they can be used interchangably\n",
    "        within this function.  For example, they both implement the `dot` method.\n",
    "\n",
    "    Args:\n",
    "        trainData (RDD of LabeledPoint): The labeled data for use in training the model.\n",
    "        numIters (int): The number of iterations of gradient descent to perform.\n",
    "\n",
    "    Returns:\n",
    "        (np.ndarray, np.ndarray): A tuple of (weights, training errors).  Weights will be the\n",
    "            final weights (one weight per feature) for the model, and training errors will contain\n",
    "            an error (RMSE) for each iteration of the algorithm.\n",
    "    \"\"\"\n",
    "    # The length of the training data\n",
    "    n = trainData.<COMPLETAR>\n",
    "    # The number of features in the training data\n",
    "    d = <COMPLETAR>\n",
    "    w = np.zeros(d)\n",
    "    alpha = 1.0\n",
    "    # We will compute and store the training error after each iteration\n",
    "    errorTrain = np.zeros(numIters)\n",
    "    for i in range(numIters):\n",
    "        # Use getLabeledPrediction from (3b) with trainData to obtain an RDD of (label, prediction)\n",
    "        # tuples.  Note that the weights all equal 0 for the first iteration, so the predictions will\n",
    "        # have large errors to start.\n",
    "        labelsAndPredsTrain = trainData.<COMPLETAR>\n",
    "        errorTrain[i] = <COMPLETAR>\n",
    "\n",
    "        # Calculate the `gradient`.  Make use of the `gradientSummand` function you wrote in (3a).\n",
    "        # Note that `gradient` sould be a `DenseVector` of length `d`.\n",
    "        gradient = trainData.<COMPLETAR>\n",
    "\n",
    "        # Update the weights\n",
    "        alpha_i = alpha / (n * np.sqrt(i+1))\n",
    "        w -= alpha_i*gradient\n",
    "    return w, errorTrain\n",
    "\n",
    "# create a toy dataset with n = 10, d = 3, and then run 5 iterations of gradient descent\n",
    "# note: the resulting model will not be useful; the goal here is to verify that\n",
    "# linregGradientDescent is working properly\n",
    "exampleN = 10\n",
    "exampleD = 3\n",
    "exampleData = (sc\n",
    "               .parallelize(parsedTrainData.take(exampleN))\n",
    "               .map(lambda lp: LabeledPoint(lp.label, lp.features[0:exampleD])))\n",
    "print exampleData.take(2)\n",
    "exampleNumIters = 5\n",
    "exampleWeights, exampleErrorTrain = linregGradientDescent(exampleData, exampleNumIters)\n",
    "print exampleWeights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# TEST Gradient descent (3c)\n",
    "expectedOutput = [48.88110449,  36.01144093, 30.25350092]\n",
    "Test.assertTrue(np.allclose(exampleWeights, expectedOutput), 'value of exampleWeights is incorrect')\n",
    "expectedError = [79.72013547, 30.27835699,  9.27842641,  9.20967856,  9.19446483]\n",
    "Test.assertTrue(np.allclose(exampleErrorTrain, expectedError),\n",
    "                'value of exampleErrorTrain is incorrect')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ** (3d) Treinando o modelo na base de dados **\n",
    "\n",
    "#### Agora iremos treinar o modelo de regressão linear na nossa base de dados de treino e calcular o RMSE na base de validação. Lembrem-se que não devemos utilizar a base de teste até que o melhor parâmetro do modelo seja escolhido. \n",
    "\n",
    "#### Para essa tarefa vamos utilizar as funções linregGradientDescent, getLabeledPrediction e calcRMSE já implementadas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# EXERCICIO\n",
    "numIters = 50\n",
    "weightsLR0, errorTrainLR0 = <COMPLETAR>\n",
    "\n",
    "labelsAndPreds = parsedValData.<COMPLETAR>\n",
    "rmseValLR0 = calcRMSE(labelsAndPreds)\n",
    "\n",
    "print 'Validation RMSE:\\n\\tBaseline = {0:.3f}\\n\\tLR0 = {1:.3f}'.format(rmseValBase,\n",
    "                                                                       rmseValLR0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# TEST Train the model (3d)\n",
    "expectedOutput = [22.64535883, 20.064699, -0.05341901, 8.2931319, 5.79155768, -4.51008084,\n",
    "                  15.23075467, 3.8465554, 9.91992022, 5.97465933, 11.36849033, 3.86452361]\n",
    "Test.assertTrue(np.allclose(weightsLR0, expectedOutput), 'incorrect value for weightsLR0')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ** Visualização 3: Erro de Treino **\n",
    "#### Vamos verificar o comportamento do algoritmo durante as iterações. Para isso vamos plotar um gráfico em que o eixo x representa a iteração e o eixo y o log do RMSE. O primeiro gráfico mostra as primeiras 50 iterações enquanto o segundo mostra as últimas 44 iterações. Note que inicialmente o erro cai rapidamente, quando então o gradiente descendente passa a fazer apenas pequenos ajustes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "norm = Normalize()\n",
    "clrs = cmap(np.asarray(norm(np.log(errorTrainLR0))))[:,0:3]\n",
    "\n",
    "fig, ax = preparePlot(np.arange(0, 60, 10), np.arange(2, 6, 1))\n",
    "ax.set_ylim(2, 6)\n",
    "plt.scatter(range(0, numIters), np.log(errorTrainLR0), s=14**2, c=clrs, edgecolors='#888888', alpha=0.75)\n",
    "ax.set_xlabel('Iteration'), ax.set_ylabel(r'$\\log_e(errorTrainLR0)$')\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "norm = Normalize()\n",
    "clrs = cmap(np.asarray(norm(errorTrainLR0[6:])))[:,0:3]\n",
    "\n",
    "fig, ax = preparePlot(np.arange(0, 60, 10), np.arange(17, 22, 1))\n",
    "ax.set_ylim(17.8, 21.2)\n",
    "plt.scatter(range(0, numIters-6), errorTrainLR0[6:], s=14**2, c=clrs, edgecolors='#888888', alpha=0.75)\n",
    "ax.set_xticklabels(map(str, range(6, 66, 10)))\n",
    "ax.set_xlabel('Iteration'), ax.set_ylabel(r'Training Error')\n",
    "pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ** Part 4: Treino utilizando MLlib e Busca em Grade (Grid Search) **"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **(4a) `LinearRegressionWithSGD` **\n",
    "\n",
    "#### Nosso teste inicial já conseguiu obter um desempenho melhor que o baseline, mas vamos ver se conseguimos fazer melhor introduzindo a ordenada de origem da reta além de outros ajustes no algoritmo.  MLlib [LinearRegressionWithSGD](https://spark.apache.org/docs/latest/api/python/pyspark.mllib.html#pyspark.mllib.regression.LinearRegressionWithSGD) implementa o mesmo algoritmo da parte (3b), mas de forma mais eficiente para o contexto distribuído e com várias funcionalidades adicionais. \n",
    "\n",
    "#### Primeiro utilize a função LinearRegressionWithSGD para treinar um modelo com regularização L2 (Ridge) e com a ordenada de origem. Esse método retorna um [LinearRegressionModel](https://spark.apache.org/docs/latest/api/python/pyspark.mllib.html#pyspark.mllib.regression.LinearRegressionModel).  \n",
    "\n",
    "#### Em seguida, use os atributos [weights](http://spark.apache.org/docs/latest/api/python/pyspark.mllib.html#pyspark.mllib.regression.LinearRegressionModel.weights) e  [intercept](http://spark.apache.org/docs/latest/api/python/pyspark.mllib.html#pyspark.mllib.regression.LinearRegressionModel.intercept) para imprimir o modelo encontrado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pyspark.mllib.regression import LinearRegressionWithSGD\n",
    "# Values to use when training the linear regression model\n",
    "numIters = 500  # iterations\n",
    "alpha = 1.0  # step\n",
    "miniBatchFrac = 1.0  # miniBatchFraction\n",
    "reg = 1e-1  # regParam\n",
    "regType = 'l2'  # regType\n",
    "useIntercept = True  # intercept"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# EXERCICIO\n",
    "firstModel = LinearRegressionWithSGD.train(parsedTrainData, iterations = numIters, step = alpha, miniBatchFraction = 1.0,\n",
    "                                          regParam=reg,regType=regType, intercept=useIntercept)\n",
    "\n",
    "# weightsLR1 stores the model weights; interceptLR1 stores the model intercept\n",
    "weightsLR1 = firstModel.<COMPLETAR>\n",
    "interceptLR1 = firstModel.<COMPLETAR>\n",
    "print weightsLR1, interceptLR1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# TEST LinearRegressionWithSGD (4a)\n",
    "expectedIntercept = 13.3335907631\n",
    "expectedWeights = [16.682292427, 14.7439059559, -0.0935105608897, 6.22080088829, 4.01454261926, -3.30214858535,\n",
    "                   11.0403027232, 2.67190962854, 7.18925791279, 4.46093254586, 8.14950409475, 2.75135810882]\n",
    "Test.assertTrue(np.allclose(interceptLR1, expectedIntercept), 'incorrect value for interceptLR1')\n",
    "Test.assertTrue(np.allclose(weightsLR1, expectedWeights), 'incorrect value for weightsLR1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **(4b) Predição**\n",
    "#### Agora use o método [LinearRegressionModel.predict()](http://spark.apache.org/docs/latest/api/python/pyspark.mllib.html#pyspark.mllib.regression.LinearRegressionModel.predict) para fazer a predição de um objeto. Passe o atributo `features` de um `LabeledPoint` comp parâmetro."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# EXERCICIO\n",
    "samplePoint = parsedTrainData.take(1)[0]\n",
    "samplePrediction = firstModel.<COMPLETAR>\n",
    "print samplePrediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# TEST Predict (4b)\n",
    "Test.assertTrue(np.allclose(samplePrediction, 56.8013380112),\n",
    "                'incorrect value for samplePrediction')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ** (4c) Avaliar RMSE **\n",
    "\n",
    "#### Agora avalie o desempenho desse modelo no teste de validação. Use o método `predict()` para criar o RDD `labelsAndPreds` RDD, e então use a função `calcRMSE()` da Parte (2b) para calcular o RMSE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# EXERCICIO\n",
    "labelsAndPreds = parsedValData.<COMPLETAR>\n",
    "rmseValLR1 = calcRMSE(labelsAndPreds)\n",
    "\n",
    "print ('Validation RMSE:\\n\\tBaseline = {0:.3f}\\n\\tLR0 = {1:.3f}' +\n",
    "       '\\n\\tLR1 = {2:.3f}').format(rmseValBase, rmseValLR0, rmseValLR1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# TEST Evaluate RMSE (4c)\n",
    "Test.assertTrue(np.allclose(rmseValLR1, 19.691247), 'incorrect value for rmseValLR1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ** (4d) Grid search **\n",
    "#### Já estamos superando o baseline em pelo menos dois anos na média, vamos ver se encontramos um conjunto de parâmetros melhor.  Faça um grid search para encontrar um bom parâmetro de regularização.  Tente valores para `regParam` dentro do conjunto `1e-10`, `1e-5`, e `1`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# EXERCICIO\n",
    "bestRMSE = rmseValLR1\n",
    "bestRegParam = reg\n",
    "bestModel = firstModel\n",
    "\n",
    "numIters = 500\n",
    "alpha = 1.0\n",
    "miniBatchFrac = 1.0\n",
    "for reg in <COMPLETAR>:\n",
    "    model = LinearRegressionWithSGD.train(parsedTrainData, numIters, alpha,\n",
    "                                          miniBatchFrac, regParam=reg,\n",
    "                                          regType='l2', intercept=True)\n",
    "    labelsAndPreds = parsedValData.<COMPLETAR>\n",
    "    rmseValGrid = calcRMSE(labelsAndPreds)\n",
    "    print rmseValGrid\n",
    "\n",
    "    if rmseValGrid < bestRMSE:\n",
    "        bestRMSE = rmseValGrid\n",
    "        bestRegParam = reg\n",
    "        bestModel = model\n",
    "rmseValLRGrid = bestRMSE\n",
    "\n",
    "print ('Validation RMSE:\\n\\tBaseline = {0:.3f}\\n\\tLR0 = {1:.3f}\\n\\tLR1 = {2:.3f}\\n' +\n",
    "       '\\tLRGrid = {3:.3f}').format(rmseValBase, rmseValLR0, rmseValLR1, rmseValLRGrid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# TEST Grid search (4d)\n",
    "Test.assertTrue(np.allclose(17.017170, rmseValLRGrid), 'incorrect value for rmseValLRGrid')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ** Visualização 5: Predições do melhor modelo**\n",
    "#### Agora, vamos criar um gráfico para verificar o desempenho do melhor modelo. Reparem nesse gráfico que a quantidade de pontos mais escuros reduziu bastante em relação ao baseline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predictions = np.asarray(parsedValData\n",
    "                         .map(lambda lp: bestModel.predict(lp.features))\n",
    "                         .collect())\n",
    "actual = np.asarray(parsedValData\n",
    "                    .map(lambda lp: lp.label)\n",
    "                    .collect())\n",
    "error = np.asarray(parsedValData\n",
    "                   .map(lambda lp: (lp.label, bestModel.predict(lp.features)))\n",
    "                   .map(lambda (l, p): squaredError(l, p))\n",
    "                   .collect())\n",
    "\n",
    "norm = Normalize()\n",
    "clrs = cmap(np.asarray(norm(error)))[:,0:3]\n",
    "\n",
    "fig, ax = preparePlot(np.arange(0, 120, 20), np.arange(0, 120, 20))\n",
    "ax.set_xlim(15, 82), ax.set_ylim(-5, 105)\n",
    "plt.scatter(predictions, actual, s=14**2, c=clrs, edgecolors='#888888', alpha=0.75, linewidths=.5)\n",
    "ax.set_xlabel('Predicted'), ax.set_ylabel(r'Actual')\n",
    "pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ** (4e) Grid Search para o valor de alfa e número de iterações **\n",
    "\n",
    "####Agora, vamos verificar diferentes valores para alfa e número de iterações para perceber o impacto desses parâmetros em nosso modelo. Especificamente tente os valores  `1e-5` e `10` para `alpha` e os valores `500` e `5` para número de iterações. Avalie todos os modelos no conjunto de valdação.  Reparem que com um valor baixo de alpha, o algoritmo necessita de muito mais iterações para convergir ao ótimo, enquanto um valor muito alto para alpha, pode fazer com que o algoritmo não encontre uma solução."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# EXERCICIO\n",
    "reg = bestRegParam\n",
    "modelRMSEs = []\n",
    "\n",
    "for alpha in <COMPLETAR>:\n",
    "    for numIters in <COMPLETAR>:\n",
    "        model = LinearRegressionWithSGD.train(parsedTrainData, numIters, alpha,\n",
    "                                              miniBatchFrac, regParam=reg,\n",
    "                                              regType='l2', intercept=True)\n",
    "        labelsAndPreds = parsedValData.map(lambda lp: (lp.label, model.predict(lp.features)))\n",
    "        rmseVal = calcRMSE(labelsAndPreds)\n",
    "        print 'alpha = {0:.0e}, numIters = {1}, RMSE = {2:.3f}'.format(alpha, numIters, rmseVal)\n",
    "        modelRMSEs.append(rmseVal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# TEST Vary alpha and the number of iterations (4e)\n",
    "expectedResults = sorted([56.969705, 56.892949, 355124752.221221])\n",
    "Test.assertTrue(np.allclose(sorted(modelRMSEs)[:3], expectedResults), 'incorrect value for modelRMSEs')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ** Parte 5: Adicionando atributos não-lineares **"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ** (5a) Interações par a par **\n",
    "\n",
    "#### Conforme mencionado em aula, os modelos de regressão linear conseguem capturar as relações lineares entre os atributos e o rótulo. Porém, em muitos casos a relação entre eles é não-linear.\n",
    "\n",
    "#### Uma forma de resolver tal problema é criando mais atributos com características não-lineares, como por exemplo a expansão quadrática dos atributos originais. Escreva uma função `twoWayInteractions` que recebe um  `LabeledPoint` e gera um novo `LabeledPoint` que contém os atributos antigos e as interações par a par entre eles. Note que um objeto com 3 atributos terá nove interações ( $ \\scriptsize 3^2 $ ) par a par.\n",
    "\n",
    "#### Para facilitar, utilize o método [itertools.product](https://docs.python.org/2/library/itertools.html#itertools.product) para gerar tuplas para cada possível interação. Utilize também [np.hstack](http://docs.scipy.org/doc/numpy/reference/generated/numpy.hstack.html#numpy.hstack) para concatenar dois vetores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# EXERCICIO\n",
    "import itertools\n",
    "\n",
    "def twoWayInteractions(lp):\n",
    "    \"\"\"Creates a new `LabeledPoint` that includes two-way interactions.\n",
    "\n",
    "    Note:\n",
    "        For features [x, y] the two-way interactions would be [x^2, x*y, y*x, y^2] and these\n",
    "        would be appended to the original [x, y] feature list.\n",
    "\n",
    "    Args:\n",
    "        lp (LabeledPoint): The label and features for this observation.\n",
    "\n",
    "    Returns:\n",
    "        LabeledPoint: The new `LabeledPoint` should have the same label as `lp`.  Its features\n",
    "            should include the features from `lp` followed by the two-way interaction features.\n",
    "    \"\"\"\n",
    "    newfeats = <COMPLETAR>\n",
    "    return LabeledPoint(lp.label, <COMPLETAR>)\n",
    "    #return lp\n",
    "    \n",
    "\n",
    "print twoWayInteractions(LabeledPoint(0.0, [2, 3]))\n",
    "\n",
    "# Transform the existing train, validation, and test sets to include two-way interactions.\n",
    "trainDataInteract = parsedTrainData.map(twoWayInteractions)\n",
    "valDataInteract = parsedValData.map(twoWayInteractions)\n",
    "testDataInteract = parsedTestData.map(twoWayInteractions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# TEST Add two-way interactions (5a)\n",
    "twoWayExample = twoWayInteractions(LabeledPoint(0.0, [2, 3]))\n",
    "Test.assertTrue(np.allclose(sorted(twoWayExample.features),\n",
    "                            sorted([2.0, 3.0, 4.0, 6.0, 6.0, 9.0])),\n",
    "                'incorrect features generatedBy twoWayInteractions')\n",
    "twoWayPoint = twoWayInteractions(LabeledPoint(1.0, [1, 2, 3]))\n",
    "Test.assertTrue(np.allclose(sorted(twoWayPoint.features),\n",
    "                            sorted([1.0,2.0,3.0,1.0,2.0,3.0,2.0,4.0,6.0,3.0,6.0,9.0])),\n",
    "                'incorrect features generated by twoWayInteractions')\n",
    "Test.assertEquals(twoWayPoint.label, 1.0, 'incorrect label generated by twoWayInteractions')\n",
    "Test.assertTrue(np.allclose(sum(trainDataInteract.take(1)[0].features), 40.821870576035529),\n",
    "                'incorrect features in trainDataInteract')\n",
    "Test.assertTrue(np.allclose(sum(valDataInteract.take(1)[0].features), 45.457719932695696),\n",
    "                'incorrect features in valDataInteract')\n",
    "Test.assertTrue(np.allclose(sum(testDataInteract.take(1)[0].features), 35.109111632783168),\n",
    "                'incorrect features in testDataInteract')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ** (5b) Construindo um novo modelo **\n",
    "\n",
    "#### Agora construa um novo modelo usando esses novos atributos. Repare que idealmente, com novos atributos, você deve realizar um novo Grid Search para determinar os novos parâmetros ótimos, uma vez que os parâmetros do modelo anterior não necessariamente funcionarão aqui.\n",
    "\n",
    "#### Para este exercício, os parâmetros já foram otimizados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# EXERCICIO\n",
    "numIters = 500\n",
    "alpha = 1.0\n",
    "miniBatchFrac = 1.0\n",
    "reg = 1e-10\n",
    "\n",
    "modelInteract = LinearRegressionWithSGD.train(trainDataInteract, numIters, alpha,\n",
    "                                              miniBatchFrac, regParam=reg,\n",
    "                                              regType='l2', intercept=True)\n",
    "labelsAndPredsInteract = valDataInteract.<COMPLETAR>\n",
    "rmseValInteract = calcRMSE(labelsAndPredsInteract)\n",
    "\n",
    "print ('Validation RMSE:\\n\\tBaseline = {0:.3f}\\n\\tLR0 = {1:.3f}\\n\\tLR1 = {2:.3f}\\n\\tLRGrid = ' +\n",
    "       '{3:.3f}\\n\\tLRInteract = {4:.3f}').format(rmseValBase, rmseValLR0, rmseValLR1,\n",
    "                                                 rmseValLRGrid, rmseValInteract)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# TEST Build interaction model (5b)\n",
    "Test.assertTrue(np.allclose(rmseValInteract, 15.6894664683), 'incorrect value for rmseValInteract')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ** (5c) Avaliando o modelo de interação **\n",
    "\n",
    "#### Finalmente, temos que o melhor modelo para o conjunto de validação foi o modelo de interação. Na prática esse seria o modelo escolhido para aplicar nos modelos não-rotulados. Vamos ver como essa escolha se sairia utilizand a base de teste nesse modelo e no baseline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# EXERCICIO\n",
    "labelsAndPredsTest = testDataInteract.<COMPLETAR>\n",
    "rmseTestInteract = calcRMSE(labelsAndPredsTest)\n",
    "\n",
    "print ('Test RMSE:\\n\\tBaseline = {0:.3f}\\n\\tLRInteract = {1:.3f}'\n",
    "       .format(rmseTestBase, rmseTestInteract))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# TEST Evaluate interaction model on test data (5c)\n",
    "Test.assertTrue(np.allclose(rmseTestInteract, 16.3272040537),\n",
    "                'incorrect value for rmseTestInteract')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
